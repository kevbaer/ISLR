---
title: "ISLR_Cha_8"
format: html
editor: visual
---

```{r}
library(tidymodels)
library(ISLR)
library(rpart.plot)
library(vip)

data("Boston", package = "MASS")
Boston <- as_tibble(Boston)
```

```{r}
Carseats <- as_tibble(Carseats) |> 
  mutate(High = factor(if_else(Sales <= 8, "No", "Yes"))) |> 
  select(-Sales)
```

```{r}
tree_spec <- decision_tree() |> 
  set_engine("rpart")

class_tree_spec <- tree_spec |> 
  set_mode("classification")

class_tree_fit <- class_tree_spec |> 
  fit(High ~ ., data = Carseats)

class_tree_fit
```

```{r}
class_tree_fit |> 
  extract_fit_engine() |> 
  rpart.plot()
```

```{r}
augment(class_tree_fit, new_data = Carseats) |> 
  accuracy(truth = High, estimate = .pred_class)
```

```{r}
augment(class_tree_fit, new_data = Carseats) |> 
  conf_mat(truth = High, estimate = .pred_class)
```

```{r}
set.seed(1234)
Carseats_split <- initial_split(Carseats)

Carseats_train <- training(Carseats_split)
Carseats_test <- testing(Carseats_split)
```

```{r}
class_tree_fit <- fit(class_tree_spec, High ~ ., data = Carseats_train)
```

```{r}
augment(class_tree_fit, new_data = Carseats_test) |> 
  conf_mat(truth = High, estimate = .pred_class)
```

```{r}
augment(class_tree_fit, new_data = Carseats_test) |> 
  accuracy(truth = High, estimate = .pred_class)
```

```{r}
class_tree_wf <- workflow() |> 
  add_model(class_tree_spec |> set_args(cost_complexity = tune())) |> 
  add_formula(High ~ .)

set.seed(1234)
Carseats_fold <- vfold_cv(Carseats_train)

param_grid <- grid_regular(cost_complexity(range = c(-3, -1)), levels = 10)

tune_res <- tune_grid(
  class_tree_wf,
  resamples = Carseats_fold,
  grid = param_grid,
  metrics = metric_set(accuracy)
)
```

```{r}
theme_set(theme_bw(base_family = "Barlow", base_size = 16))
autoplot(tune_res)
```

```{r}
best_complexity <- select_best(tune_res)
class_tree_final <- finalize_workflow(class_tree_wf, best_complexity)

class_tree_final_fit <- fit(class_tree_final, data = Carseats_train)

class_tree_final_fit
```

```{r}
class_tree_final_fit |> 
  extract_fit_engine() |> 
  rpart.plot()
```

```{r}
reg_tree_spec <- tree_spec |> 
  set_mode("regression")
```

```{r}
set.seed(1234)
Boston_split <- initial_split(Boston)

Boston_train <- training(Boston_split)
Boston_test <- testing(Boston_split)
```

```{r}
reg_tree_fit <- fit(reg_tree_spec, medv ~ ., Boston_train)
reg_tree_fit
```

```{r}
augment(reg_tree_fit, new_data = Boston_test) |> 
  rmse(truth = medv, estimate = .pred)
```

```{r}
reg_tree_fit  |> 
  extract_fit_engine()  |> 
  rpart.plot()
```

```{r}
reg_tree_wf <- workflow()  |> 
  add_model(reg_tree_spec  |> set_args(cost_complexity = tune()))  |> 
  add_formula(medv ~ .)

set.seed(1234)
Boston_fold <- vfold_cv(Boston_train)

param_grid <- grid_regular(cost_complexity(range = c(-4, -1)), levels = 10)

tune_res <- tune_grid(
  reg_tree_wf, 
  resamples = Boston_fold, 
  grid = param_grid
)
```

```{r}
autoplot(tune_res)
```

```{r}
best_complexity <- select_best(tune_res, metric = "rmse")

reg_tree_final <- finalize_workflow(reg_tree_wf, best_complexity)

reg_tree_final_fit <- fit(reg_tree_final, data = Boston_train)
reg_tree_final_fit
```

```{r}
reg_tree_final_fit  |> 
  extract_fit_engine()  |> 
  rpart.plot()
```

```{r}
bagging_spec <- rand_forest(mtry = .cols()) |> 
  set_engine("randomForest",importance = TRUE ) |> 
  set_mode("regression")

bagging_wf <- workflow() |> 
  add_model(bagging_spec) |> 
  add_formula(medv ~ .)

bagging_fit <- fit(bagging_wf, data = Boston_train)

augment(bagging_fit, new_data = Boston_test) |> 
  rmse(truth = medv, estimate = .pred)
```

```{r}
augment(bagging_fit, new_data = Boston_test) |> 
  ggplot() +
  aes(medv, .pred) + 
  geom_abline() +
  geom_point(alpha = .5)
```

```{r}
library(important)
j <- importance_perm(bagging_fit, data = Boston_train, type = "original")

autoplot(j, metric = "rmse")

j |> 
  filter(.metric == "rmse") |> 
  arrange(importance) |> 
  ggplot() +
  aes(importance, forcats::fct_inorder(predictor)) +
  geom_col() +
  scale_x_continuous(expand = expansion(c(0.005, 0.06))) +
  labs(y = "predictor")
```

```{r}
rf_spec <- rand_forest(mtry = 6) |> 
  set_engine("randomForest") |> 
  set_mode("regression")


rf_wf <- workflow() |> 
  add_model(rf_spec) |> 
  add_formula(medv ~ .)

rf_fit <- fit(rf_wf, data = Boston_train)

augment(rf_fit, new_data = Boston_test) |> 
  rmse(truth = medv, estimate = .pred)
```

```{r}
j <- importance_perm(rf_fit, data = Boston_train, type = "original")


j |> 
  filter(.metric == "rmse") |> 
  arrange(importance) |> 
  ggplot() +
  aes(importance, forcats::fct_inorder(predictor)) +
  geom_col() +
  scale_x_continuous(expand = expansion(c(0.005, 0.06))) +
  labs(y = "predictor")
```

```{r}
boost_spec <- boost_tree(trees = 5000, tree_depth = 4) |> 
  set_engine("xgboost") |> 
  set_mode("regression")

boost_wf <- workflow() |> 
  add_model(boost_spec) |> 
  add_formula(medv ~ .)

boost_fit <- fit(boost_wf, data = Boston_train)

augment(boost_fit, new_data = Boston_test)  |> 
  rmse(truth = medv, estimate = .pred)
```

```{r}
j <- importance_perm(boost_fit, data = Boston_train, type = "original")

j |> 
  filter(.metric == "rmse") |> 
  arrange(importance) |> 
  ggplot() +
  aes(importance, forcats::fct_inorder(predictor)) +
  geom_col() +
  scale_x_continuous(expand = expansion(c(0.005, 0.06))) +
  labs(y = "predictor")
```

```{r}
Bart_spec <- bart() |> 
  set_engine("dbarts") |> 
  set_mode("regression")

Bart_wf <- workflow() |> 
  add_model(Bart_spec) |> 
  add_formula(medv ~ .)

Bart_fit <- fit(Bart_wf, Boston_train)

augment(Bart_fit, new_data = Boston_test) |> 
  rmse(truth = medv, estimate = .pred)
```

```{r}
j <- importance_perm(Bart_fit, data = Boston_train, type = "original")

j |> 
  filter(.metric == "rmse") |> 
  arrange(importance) |> 
  ggplot() +
  aes(importance, forcats::fct_inorder(predictor)) +
  geom_col() +
  scale_x_continuous(expand = expansion(c(0.005, 0.06))) +
  labs(y = "predictor")
```

```{r}
set.seed(11042004)

xgb_tun_folds <- vfold_cv(Boston_train, strata = medv, v = 10, repeats = 3)

xgb_spec <-
  boost_tree(
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune(),
    min_n = tune(),
    sample_size = tune(),
    trees = tune()
  ) |>
  set_engine("xgboost") |>
  set_mode("regression")

xgb_wf <- workflow() |> 
  add_model(xgb_spec) |> 
  add_formula(medv ~ .)
```

```{r}
mirai::daemons(7)

tune_results <- tune_grid(
  xgb_wf,
  xgb_tun_folds,
  grid = 50,
  metrics = metric_set(rmse)
)

mirai::daemons(0)
```

```{r}
xgb_final <- finalize_workflow(xgb_wf, select_best(tune_results, metric = "rmse"))
```

```{r}
xgb_final_fit <- fit(xgb_final, Boston_train)

augment(xgb_final_fit, new_data = Boston_test) |> 
  rmse(truth = medv, estimate = .pred)
```

```{r}
j <- importance_perm(xgb_final_fit, data = Boston_train, type = "original", times = 50)

j |> 
  filter(.metric == "rmse") |> 
  arrange(importance) |> 
  ggplot() +
  aes(importance, forcats::fct_inorder(predictor)) +
  geom_col() +
  scale_x_continuous(expand = expansion(c(0.005, 0.06))) +
  labs(y = "predictor")
```

```{r}
library(DALEXtra)
library(forcats)

ggplot_imp <- function(...) {
  {
    obj <- list(...)
    metric_name <- attr(obj[[1]], "loss_name")
    metric_lab <- "Permutation Based Variable Importance"

    full_vip <- bind_rows(obj) %>%
      filter(variable != "_baseline_")

    perm_vals <- full_vip %>%
      filter(variable == "_full_model_") %>%
      group_by(label) %>%
      summarise(dropout_loss = mean(dropout_loss))

    p <- full_vip %>%
      filter(variable != "_full_model_") %>%
      mutate(variable = fct_reorder(variable, dropout_loss)) %>%
      ggplot(aes(dropout_loss, variable))


      p +
        # geom_boxplot(fill = "#91CBD765", alpha = 0.4)
        geom_col(fill = "#B80A50") +
        scale_x_continuous(expand = expansion(mult= (c(0.005, 0.06))))+
      theme(legend.position = "none") +
      labs(
        x = metric_lab,
        y = NULL, fill = NULL, color = NULL
      )
  }
}
```

```{r}
Boston_explainer_xgb <-
  explain_tidymodels(
    xgb_final_fit,
    data = Boston_train |> select(-medv),
    y = Boston_train$medv,
    label = "xgb",
    verbose = FALSE
  ) |> model_parts()

ggplot_imp(Boston_explainer_xgb)
```
