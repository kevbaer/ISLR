---
title: "ISLr_Chap_a10"
format: html
editor: visual
---

### using <https://hastie.su.domains/ISLR2/Labs/Rmarkdown_Notebooks/Ch10-deeplearning-lab-torch.html>

```{r}
library(ISLR2)
library(tidymodels)
Gitters <- na.omit(Hitters)
n <- nrow(Gitters)
set.seed(13)
ntest <- trunc(n / 3)
testid <- sample(1:n, ntest)
Gitter_train <- Gitters[-testid, ]
Gitter_test <- Gitters[testid, ]

lm_spec <- linear_reg() |> 
  set_mode("regression") |> 
  set_engine("lm")

lm_fit <- fit(lm_spec, formula = Salary ~ ., data = Gitter_train)
```

```{r}
lm_fit |> 
  augment(new_data = Gitter_test) |> 
  mae(truth = Salary, estimate = .pred)
```

```{r}
lasso_spec <- linear_reg(mixture = 1, penalty = .15) |> # too lazy to CV
  set_mode("regression") |> 
  set_engine("glmnet")

lasso_fit <- fit(lasso_spec, formula = Salary ~ ., data = Gitter_train)

lasso_fit |> 
  augment(new_data = Gitter_test) |> 
  mae(truth = Salary, estimate = .pred)
```

```{r}
library(torch)
library(luz)
library(torchvision)
library(torchdatasets)
library(zeallot)
torch_manual_seed(13)
```

```{r}
modnn <- nn_module(
  initialize = function(input_size){
    self$hidden <- nn_linear(input_size, 50)
    self$activation <- nn_relu()
    self$dropout <- nn_dropout(0.4)
    self$output <- nn_linear(50, 1)
  },
  forward = function(x){
    x |> 
      self$hidden() |> 
      self$activation() |> 
      self$dropout() |> 
      self$output()
  }
)
```

```{r}
x <- scale(model.matrix(Salary ~ . - 1, data = Gitters))
y <- Gitters$Salary
```

```{r}
modnn <- modnn |> 
  setup(
    loss = nn_mse_loss(),
    optimizer = optim_rmsprop,
    metrics = list(luz_metric_mae())
  ) |> 
  set_hparams(input_size = ncol(x))
```

```{r}
fitted <- modnn |> 
  fit(
    data = list(x[-testid, ], matrix(y[-testid], ncol = 1)),
    valid_data = list(x[testid, ], matrix(y[testid], ncol = 1)),
    epochs = 20
  )
```

```{r}
theme_set(theme_bw(base_family = "Barlow", base_size = 16))
plot(fitted)
```

```{r}
npred <- predict(fitted, x[testid, ])
mean(abs(y[testid] - as.matrix(npred)))
```

```{r}
train_ds <- mnist_dataset(root = ".", train = TRUE, download = TRUE)
test_ds <- mnist_dataset(root = ".", train = FALSE, download = TRUE)

str(train_ds[1])
```

```{r}
transform <- function(x){
  x |> 
    torch_tensor() |> 
    torch_flatten() |> 
    torch_div(255)
}
train_ds <- mnist_dataset(
  root = ".",
  train = TRUE,
  download = TRUE,
  transform = transform
)

test_ds <- mnist_dataset(
  root = ".",
  train = FALSE,
  download = TRUE,
  transform = transform
)
```

```{r}
modelnn <- nn_module(
  initialize = function() {
    self$linear1 <- nn_linear(in_features = 28*28, out_features = 256)
    self$linear2 <- nn_linear(in_features = 256, out_features = 128)
    self$linear3 <- nn_linear(in_features = 128, out_features = 10)
    
    self$drop1 <- nn_dropout(p = 0.4)
    self$drop2 <- nn_dropout(p = 0.3)
    
    self$activation <- nn_relu()
  },
  forward = function(x) {
    x %>% 
      
      self$linear1() %>% 
      self$activation() %>% 
      self$drop1() %>% 
      
      self$linear2() %>% 
      self$activation() %>% 
      self$drop2() %>% 
      
      self$linear3()
  }
)
```

```{r}
print(modelnn())
```

```{r}
modelnn <- modelnn %>% 
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_rmsprop, 
    metrics = list(luz_metric_accuracy())
  )
```

```{r}
system.time(
   fitted <- modelnn %>%
      fit(
        data = train_ds, 
        epochs = 10, #15, 
        valid_data = 0.2,
        dataloader_options = list(batch_size = 256),
        verbose = TRUE
      )
 )
```

```{r}
plot(fitted)
```

```{r}
accuracy <- function(pred, truth) {
   mean(pred == truth) }

# gets the true classes from all observations in test_ds.
truth <- sapply(seq_along(test_ds), function(x) test_ds[x][[2]])

fitted %>% 
  predict(test_ds) %>% 
  torch_argmax(dim = 2) %>%  # the predicted class is the one with higher 'logit'.
  as_array() %>% # we convert to an R object
  accuracy(truth)
```

```{r}
modellr <- nn_module(
  initialize = function() {
    self$linear <- nn_linear(784, 10)
  },
  forward = function(x) {
    self$linear(x)
  }
)
print(modellr())
```

```{r}
fit_modellr <- modellr %>% 
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_rmsprop,
    metrics = list(luz_metric_accuracy())
  ) %>% 
  fit(
    data = train_ds, 
    epochs = 5,
    valid_data = 0.2,
    dataloader_options = list(batch_size = 128)
  )

fit_modellr %>% 
  predict(test_ds) %>% 
  torch_argmax(dim = 2) %>%  # the predicted class is the one with higher 'logit'.
  as_array() %>% # we convert to an R object
  accuracy(truth)
```

#### stop at cnn's, pick up tomorrow
